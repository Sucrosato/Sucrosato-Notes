## 概述
- 问题的提出
    避免CPU空等
    CPU-缓存-主存
    程序访问的局部性原理
        不久的将来，访问数据或相邻数据很可能被再次访问（簇聚）
#### 工作原理
Cache地址意义不大，不需要形成
![[Pasted image 20250425094609.png]]
$M>>C$，块大小相同，块内地址完全相同
访问时，与标记逐一比对，如果相等则有对应数据
- 命中，未命中
    命中：主存块调入缓存，建立对应关系
    未命中：未调入，未建立
- 命中率
    与容量、块长有关
块长：一个存取周期内从主存调出的信息长度 n体交叉->块长为n
Cache-主存系统的效率
$$e=\frac{访问Cache的时间}{平均访问时间}=\frac{t_c}{ht_c+(1-h)t_m}\in [\frac{t_c}{t_m},1]$$
变化后：访问Cache失败后再访问内存，写出变化后的公式？
#### 基本结构
![[Pasted image 20250425101717.png]]
Cache
主存-Cache地址映射变换机构
Cache替换机构
#### 读写操作
- 读
![[Pasted image 20250425102340.png]]
- 写
    需要解决Cache和主存的一致性问题
    - 写直达法 Write-through
        一直一致，但是可能会对内存重复访问
    - 写回法 Write-back
        Cache可以不写入主存
        仅当块内容被替换掉时才写入主存
        保证不了实时一致，多处理器（并行）需要处理问题
#### 改进
1. 增加Cache级数
    片内、片外、多核（至少3级）
2. 统一缓存和分立缓存
    指令Cache、数据Cache
## Cache-主存地址映射
1. 直接映射
    ![[Pasted image 20250425113805.png]]
    取模->放到哪个字块
    区号->标记
    - 结构简单、速度快
    - 利用率低、冲突概率大
2. 全相联映射
    ![[Pasted image 20250425114148.png]]
    电路复杂、速度慢
    要同时比较t+c位，比较器更大
3. 组相连映射
    折中
    Cache分为Q组
    $$i=j~mod~Q$$
    ![[Pasted image 20250425114533.png]]
    r+1个比较器
    r=0->直接相连 r=c->全相联
## 替换算法
1. FIFO
    不能体现局部性原理
2. LRU *Last Recently Used*
    替换出近期用得最少的字块
    