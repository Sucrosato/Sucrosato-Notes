回归 -> 分类
单输出 -> 多输出：每一种分类的置信度
需要对正确项预测的值远大于其他项
softmax算子：让向量的所有值非负且和为1,得到置信度
$$softmax(\vec{o}) = \hat{\vec{y}},~\hat y_{i} = \frac{e^{o_{i}}}{\sum_{k}e^{o_{k}}}$$
交叉熵损失
对y交叉熵损失：
- 只关心正确类的预测值

## 损失函数
- L2 Loss
    似然函数？
    离得越远，梯度越大
- L1 Loss
    梯度绝对值不变
- Huber's Robust Loss
    近处是L2，远处是L1
    结合了两者优点
## 图像分类数据集
