# 预训练
%%李宇航%%
## 相关进展
领域：多模态；推理能力；开源-本地化；架构；；
不足：
## 预训练
数据来源：
分词：WordPiece，BPE（大词库）
## 模型框架设计
#### Transformer网络
512\*n维矩阵->分别\*Q,K,V（超参数）得到相关性
输入BOS预测
#### 模型效果评测
正确率
# 大语言模型微调简介
%%许洲宁%%
目的：符合偏好
分类：
- 全参数
- 参数高效微调PEFT：
    Adapter Tuning：插入轻量适配器模块-训练
    LoRA: 训练低秩矩阵（$A_{dr}, B_{rd}$）->QKV

- 基于人类反馈：
    Reward Model打分
    利用偏序对训练奖励模型：分数->好坏
- 强化学习
    PPO, GRPO
    DPO

 - 基尔霍夫
CT图像[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[
